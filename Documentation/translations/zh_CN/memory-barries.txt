
====
声明
====

本文档并不是一份规范，并且有意（为了简洁）或者无意中（由于人类天性）存在不完整的部分。这
份文档旨在为使用Linux所提供的多种内存屏障提供一份指南，但是如果有任何（可能有很多）疑惑
请询问。一些疑惑可能可以通过参考正式的内存一致性模型以及相关的tools/memory-model下的文
档得到解决。然而xxxxxx

再次声明，这份文档不是Linux用来约束硬件的规范。

这份文档的目标由两部分组成：

 （1）明确说明对于任何特定的屏障所能依靠的最低限度功能，以及

 （2）提供一份可用屏障的使用指南

需要注意的是特定的架构可以提供任何超出最低限度要求的内存屏障，但是如果任何架构的实现不满
足所需要的最低限度要求，那么该架构的实现是不正确的。

同时也需要注意的是某一特定的屏障对于某一特定的架构来说可能是空操作，因为对于该架构来说在
这种场景下一个显示的屏障是不必要的。

====
目录
====

 （*）内存访问模型概述

     - 设备操作
     - 保证

 （*）什么是内存屏障？

     - 内存屏障的类型
     - 对于内存屏障的不能假设什么？
     - 数据依赖屏障（历史）
     - 控制依赖
     - SMP屏障对
     - 内存屏障序列示例
     - 读内存屏障 vs 加载推测
     - 多重复制的原子性

 （*）显式内核屏障

     - 编译器屏障
     - CPU内存屏障

 （*）隐式内核内存屏障

     - 锁获取函数
     - 中断禁用函数
     - 睡眠和唤醒函数
     - 其他函数

 （*）CPU间获取屏障的影响

     - 获取 vs 内存访问

 （*）哪里需要使用内存屏障？

     - 处理器间交互
     - 原子操作
     - 设备访问
     - 中断禁用函数

 （*）内核I/O屏障的影响

 （*）设想的最低限度的执行顺序模型

 （*）CPU缓存的影响

     - 缓存一致性
     - 缓存一致性 vs DMA
     - 缓存一致性 vs MMIO

 （*）CPU要做的事情？

     - Alpha架构的实现
     - 虚拟机

 （*）示例用法

     - 环形缓冲区

 （*）参考文献

===============
内存访问模型概述
===============

考虑下图所示的系统抽象模型：

		            :                :
		            :                :
		            :                :
		+-------+   :   +--------+   :   +-------+
		|       |   :   |        |   :   |       |
		|       |   :   |        |   :   |       |
		| CPU 1 |<----->| Memory |<----->| CPU 2 |
		|       |   :   |        |   :   |       |
		|       |   :   |        |   :   |       |
		+-------+   :   +--------+   :   +-------+
		    ^       :       ^        :       ^
		    |       :       |        :       |
		    |       :       |        :       |
		    |       :       v        :       |
		    |       :   +--------+   :       |
		    |       :   |        |   :       |
		    |       :   |        |   :       |
		    +---------->| Device |<----------+
		            :   |        |   :
		            :   |        |   :
		            :   +--------+   :
		            :                :

每个CPU都在执行一个能够产生内存访问操作的程序。在所示的抽象CPU中，内存操作顺序是非常松散
的，在保证程序的因果关系的情况下，每个CPU都可以按照它想要的顺序执行内存操作。同样的，在
不明显的影响程序操作的情况下，编译器也能够将指令按照任何他想要的顺序进行排列。

所以在上图中，一个CPU执行内存操作的效果会被系统剩余的部分观测到，因为所执行的内存操作需
要穿越CPU与系统剩余部分的连接接口（图中虚线部分）。

比如，考虑以下事件序列：

	CPU 1		CPU 2
	===============	===============
	{ A == 1; B == 2 }
	A = 3;		x = B;
	B = 4;		y = A;

内存系统所能看到的访问集合可能有24中不同的组合：

	STORE A=3,	STORE B=4,	y=LOAD A->3,	x=LOAD B->4
	STORE A=3,	STORE B=4,	x=LOAD B->4,	y=LOAD A->3
	STORE A=3,	y=LOAD A->3,	STORE B=4,	x=LOAD B->4
	STORE A=3,	y=LOAD A->3,	x=LOAD B->2,	STORE B=4
	STORE A=3,	x=LOAD B->2,	STORE B=4,	y=LOAD A->3
	STORE A=3,	x=LOAD B->2,	y=LOAD A->3,	STORE B=4
	STORE B=4,	STORE A=3,	y=LOAD A->3,	x=LOAD B->4
	STORE B=4, ...
	...

因此会产生四种不同的结果：

	x == 2, y == 1
	x == 2, y == 3
	x == 4, y == 1
	x == 4, y == 3

除此以外，由一个CPU发起的存储操作（STORE）可能不会被由另外一个CPU发起的加载操作（LOAD）
观察到，因为存储操作有可能已经执行完成了。

考虑以下事件序列作为一个更进一步的例子：

	CPU 1		CPU 2
	===============	===============
	{ A == 1, B == 2, C == 3, P == &A, Q == &C }
	B = 4;		Q = P;
	P = &B;		D = *Q;

这里有一个明显的数据依赖关系，CPU 2赋给D的数据依赖从P中获取的内存地址。在这个执行序列结
束时，以下的结果都是可能发生的：

	(Q == &A) and (D == 1)
	(Q == &B) and (D == 2)
	(Q == &B) and (D == 4)

需要注意的是CPU 2永远不会尝试将C赋给D，因为CPU在处理*Q的加载操作前需要先将P赋给Q。

设备操作
-------

一些设备将他们的控制接口以内存地址的形式呈现，但是对于这种场景控制寄存器的访问顺序非常重
要。 比如，想象这样一个场景，一个网卡的一组内部寄存器通过一个地址端口寄存器（A）和一个数
据端口寄存器（D）进行访问。通过以下代码读取内部寄存器5：

	*A = 5;
	x = *D;

但是这个操作可能实际上以以下任意一种顺序执行：

	STORE *A = 5, x = LOAD *D
	x = LOAD *D, STORE *A = 5

第二重执行顺序几乎可以肯定会造成功能异常，因为他在读取数据寄存器之后才设置了寄存器的地址。

保证
----

对于一个CPU有一些最低限度的要求：

 （*）对于任意CPU，存在依赖关系的内存访问会按照自身的顺序被CPU顺序执行。这意味着对于以下
      访问：

	Q = READ_ONCE(P); D = READ_ONCE(*Q);

      CPU会执行以下的内存操作：

	Q = LOAD P, D = LOAD *Q

      并且总是按照这个顺序执行。然而在DEC Alpha机器上，READ_ONCE()操作也会发射一条内存
      屏障指令，随意对于DEC Alpha而言CPU会执行下边的内存操作：

	Q = LOAD P, MEMORY_BARRIER, D = LOAD *Q, MEMORY_BARRIER

      不管在DEC Alpha还是在其他架构上，READ_ONCE()总是可以阻止编译器的恶作剧。

 （*）对于某一特定的CPU而言，交叠的加载和存储操作对于该CPU总是按顺序执行的。这意味着对于
      以下操作：

	a = READ_ONCE(*X); WRITE_ONCE(*X, b);

      CPU只会按照以下顺序执行内存操作：

	a = LOAD *X, STORE *X = b

      对于：

	WRITE_ONCE(*X, c); d = READ_ONCE(*X);

      CPU只会执行：

	STORE *X = c, d = LOAD *X

     （如果交叠的加载和存储访问有交叠的内存区域）

同时有以下事情假设CPU会做或者一定不会做：

 （*）如果对内存的访问没有通过READ_ONCE()和WRITE_ONCE()进行，不能假设编译器会按照你想
      要的顺序进行内存访问。如果不适用这两个宏，编译器有权利对访问顺序进行“创造性”的重
      排，对于这部分在“编译器屏障”一节进行描述。

 （*）不能假设独立的加载和存储会按照给定的顺序执行。这意味着对于：

	X = *A; Y = *B; *D = Z;

      我们可能得到以下任一执行序列：

	X = LOAD *A,  Y = LOAD *B,  STORE *D = Z
	X = LOAD *A,  STORE *D = Z, Y = LOAD *B
	Y = LOAD *B,  X = LOAD *A,  STORE *D = Z
	Y = LOAD *B,  STORE *D = Z, X = LOAD *A
	STORE *D = Z, X = LOAD *A,  Y = LOAD *B
	STORE *D = Z, Y = LOAD *B,  X = LOAD *A

 （*）必须假设交叠的内存访问可能会被合并或丢弃。这意味着对于：

	X = *A; Y = *(A + 4);

     我们可能会获取以下的任一执行顺序：

	X = LOAD *A; Y = LOAD *(A + 4);
	Y = LOAD *(A + 4); X = LOAD *A;
	{X, Y} = LOAD {*A, *(A + 4) };

     对于：

	*A = X; *(A + 4) = Y;

     我们可能得到以下任一执行序列：

	STORE *A = X; STORE *(A + 4) = Y;
	STORE *(A + 4) = Y; STORE *A = X;
	STORE {*A, *(A + 4) } = {X, Y};

并且有以下相反的保证：

 （*）以上这些保证不适用于位域，因为编译器经常生成代码来修改使用非原子的读-修改-写操作序
      列。不要尝试使用位域来同步并行算法。

 （*）即使在位域操作被锁保护的场景下，特定位域的所有域段都必须被同一把锁保护。如果两个不
      同的域段分别被不同的锁保护，编译器非原子的读-修改-写操作序列对于一个域段的更新会污
      染存储在相邻域段中的数据。

 （*）这些保证仅仅适用于正确对齐和正确大小的标量变量。“正确大小”当前意味着变量具有与标准
      的"char", "short", "int" 和 "long" 类型一样的大小。“正确对齐”意味着自然对齐，对
      于“char”没有限制，“short”需要2字节对齐，“int”需要4字节对齐，“long”需要4字节（32
      位系统）或者8字节（64位系统）对齐。需要注意的是这些保证由C11标准中引入，因此对于
      C11之前的老版本处理器（比如gcc 4.6）需要额外注意。对于这部分保证的标准描述在3.14
      节，对于“内存位置”的定义如下：

	内存位置：
		无论是标量类型的对象还是最大序列的相邻位域都具有非零的宽度。

		注1：两个线程更新或访问不同的内存位置时不会彼此干扰。

		注2：位域和相邻的非位域成员在不同的内存位置中。这对于两个位域同样适用，
		如果一个位域在一个嵌套的结构体中声明而另一个不是，或者两个位域通过一个
		零长度的位域声明分隔，或者两个位域由一个非位域的成员变量分隔，那么这两
		个位域就处在不同的内存位置。如果声明在同一个结构体中的两个位域之间的成
		员均为位域，那么，无论这些位域的大小是多少，对于这两个位域并发的进行更
		新都是不安全的。

=============
什么是内存屏障
=============

如上所述，独立的内存操作实际上可以按照随机的顺序执行，对于CPU-CPU间的交互或者I/O交互而
言这种随机执行顺序会成为一个问题。我们需要一些方法来干预指示编译器和CPU来限制内存操作的
顺序。

内存屏障就是这种所需要的干预方法，对于屏障两端的内存操作进行一种可以观测的针对部分指令的
排序。

这种强制排序十分重要，因为在同一系统中的CPU和外设可能使用多种方式来提升性能，包括对于内
存操作进行顺序重排，延迟下发或者聚合；对内存加载进行预测；对分支进行预测以及一系列种类的
缓存。内存屏障用来重载或者抑制这些优化，从而允许代码正确的控制多个CPU和（或）设备之间的
交互。

内存屏障的类型
-------------

内存屏障有四种基本类型：

 （1）写（存储）内存屏障

     写屏障保证对于系统中的其他组件而言，所有在屏障之前的STORE（存储）操作发生在屏障之
     后的所有STORE操作之前。

     写屏障是一种仅针对存储操作的部分排序；不要求对于加载操作有任何的效果。

     可以观察随着时间顺序，CPU向内存系统提交了一系列的存储操作。所有在写屏障之前的存储
     操作均会发生在所有写屏障之后的存储操作前面。

     [!] 需要注意的是通常写屏障会合读或者数据依赖屏障一起使用；参考“SMP屏障对”子节。

 （2）数据依赖屏障

     数据依赖屏障是一种弱类型的读屏障。在这样一种需要执行两次加载操作，且第二次加载需要
     依赖第一次加载操作的执行结果（比如，通过第一次加载操作获取第二次加载操作需要访问的
     地址）的场景下，需要使用数据依赖屏障来确保第二次加载的目标数据在第一次加载获取到目
     标地址后才进行更新。

     数据依赖屏障是一种仅针对互相依赖的加载操作的部分排序；不要求对存储操作，独立的加载
     操作或者交叠的加载操作之间有任何影响。

     就像（1）中提到的，系统中的其他CPU可以看作在向内存系统提交一系列的存储操作，而待考
     察的CPU可以观察到这些操作。由待考察的CPU所发出的数据依赖屏障能够保证在屏障之前且访
     问其他CPU发出的存储操作的数据的任何加载操作在屏障之前得到执行；当屏障操作完成时，任
     何屏障之前且被加载操作访问的存储操作的效果，对于屏障之后发出的任何存储操作都是可见
     的。

     参考“内存屏障序列示例”子节中关于顺序限制的示意图。

     [!] 需要注意的是第一次加载操作必须要是真的具有一个*数据*依赖而不是一个控制依赖。如
     果第二次加载的地址依赖第一次加载操作，但是依赖关系是通过条件而不是实际加载地址，那
     么这种依赖是一种控制依赖并且需要一个完整的读屏障或更强类型的屏障来保证顺序。参考“控
     制依赖”子节获取更多的信息。

     [!] 注意正常情况下数据依赖屏障需要和写屏障成对使用；参考“SMP屏障对”子节。

 （3）读（加载）内存屏障

     读屏障是一种数据依赖屏障同时能够保证对于系统中的其他部分而言，所有屏障之后的LOAD操
     作看起来发生在屏障之前的所有LOAD操作之后。

     读屏障是一种仅针对加载操作的部分排序；不要求对存储操作有任何影响。

     读屏障中隐含有数据依赖屏障，因此可以替换数据依赖屏障。

     [!] 注意通常情况下读屏障需要和写屏障成对使用；参考“SMP屏障对”子节。

 （4）通用内存屏障

     通用内存屏障保证对于系统中的其他部分而言，所有在屏障之前的LOAD和STORE操作看起来发
     生在屏障之后的所有LOAD和STORE操作之后。

     通用内存屏障是一种同时针对加载和存储操作的部分排序。

     通用内存屏障隐含有读屏障和写屏障，因此可以替换读屏障和写屏障。

以及一些隐式的内存屏障类型：

 （5）ACQUIRE操作

     ACQUIRE操作的作用类似一种单向的内嵌屏障。它保证对于系统中的其他部分而言，所有在
     ACQUIRE操作之后的内存操作看起来发生在ACQUIRE操作之后。ACQUIRE操作包括LOCK操作和
     smp_load_acquire()以及smp_cond_load_acquire()操作。

     在ACQUIRE操作之前的内存操作可能看起来在它之后完成。

     在大部分情况下ACQUIRE操作应该总是和RELEASE操作成对使用。

 （6）RELEASE操作

     RELEASE操作的作用同样于类似一种单向的内嵌屏障。他保证对于系统中的其他部分而言，所
     有在RELEASE操作之前的内存操作看起来发生在RELEASE操作之前。RELEASE操作包括UNLOCK
     操作和smp_store_release()操作。

     在RELEASE操作之后的内存操作可能看起来在它之前完成。

     通常使用ACQUIRE和RELEASE操作时不需要使用其他的内存屏障。需要补充的是，不能保证
     RELEASE+ACQUIRE组合的效果和完整的内存屏障一样。然而，对于指定的变量使用ACQUIRE操
     作之后，任何在对于同一变量的RELEASE操作之前的内存操作能够保证可见性。换句话说，在
     指定变量的临界区内，该变量之前所有临界区的访问能够保证已经完成。

     这意味着ACQUIRE操作的作用类似于一种最低限度的“获取”操作而RELEASE操作类似于一种最
     低限度的“释放”操作。

部分在atomic_t.txt中描述的原子操作除了完全保序和松弛顺序（不含屏障语义）的定义外具有含有
ACQUIRE和RELEASE操作的变体。对于含有加载和存储操作的复合原子操作，ACQUIRE语义仅对于加载
部分生效，而RELEASE语义仅对于存储部分生效。

仅仅在可能需要两个CPU之间或CPU和设备之间进行交互的场景中需要使用内存屏障。如果能够保证在
任何特定的代码中没有这种交互场景，那么就没有使用内存屏障的需要。

需要注意的是以上仅仅是对于内存屏障最低限度保证的描述。不同的体系结构可能会提供更多的关于
内存屏障的保证，但是在特定的体系结构的代码之外不应该依赖这些保证。

对于内存屏障的不能假设什么？
-------------------------

Linux内核的内存屏障不能保证以下特定场景：

 （*）不能保证内存屏障之前的内存操作在内存屏障指令完成之前完成；屏障可以看作在CPU的访问
     队列中画了一条线，适用类型的操作不会逾越这条线。

 （*）不能保证在一个CPU上发出的内存屏障会对系统中的其他CPU或硬件设备有直接的影响。间接的
     影响在于其他CPU观察到的指定CPU的内存访问的生效顺序，但是有一点需要注意：

 （*）不能保证指定的CPU能够观测到另外一个CPU的内存访问的正确生效顺序，即使另外一个CPU使
     用了内存屏障；除非指定的CPU同时使用了配对的内存屏障（参考“SMP屏障对”子节）。

 （*）不能保证一些CPU之外的硬件设备[*]不会对内存访问进行重新排序。CPU的缓存一致性机制应
     该正确的传递CPU间内存屏障的间接效果，但是也可能不会。

	[*] 关于bus mastering DMA设备以及一致性的信息可以阅读：

	    Documentation/driver-api/pci/pci.rst
	    Documentation/core-api/dma-api-howto.rst
	    Documentation/core-api/dma-api.rst

数据依赖屏障（历史）
-----------------

在v4.15的Linux内核中，一条smp_mb()操作被添加到了DEC Alpha架构的READ_ONCE()实现中。这
意味着只有那些工作内容在DEC Alpha的架构代码或者READ_ONCE()宏上的人需要关注本节。对于那
些有需要或者仅仅是对历史感兴趣的人，本节也包含数据依赖屏障的历史。

对于数据依赖屏障的使用需要是有一些微妙且不易察觉的，并且在他们需要的地方并不总是那么明显。
为了描述它的使用需要，考虑以下事件序列：

	CPU 1		      CPU 2
	===============	      ===============
	{ A == 1, B == 2, C == 3, P == &A, Q == &C }
	B = 4;
	<write barrier>
	WRITE_ONCE(P, &B);
			      Q = READ_ONCE(P);
			      D = *Q;

这里存在一个显而易见数据依赖，可以看出在操作结束时Q的值肯定是&A或者&B，并且：

	(Q == &A) 意味着 (D == 1)
	(Q == &B) 意味着 (D == 4)

但是CPU 2观测到的P的值的更新可能在它观测到的B的值的更新之前，因此导致以下情况：

	(Q == &B) 并且 (D == 2) ????

虽然这种情况可能看起来像是一种一致性或者因果关系异常，但是并不是，并且这种行为可以在特定
的真实的CPU上观测到（比如DEC Alpha）。

为了处理这种场景，需要在地址加载和数据加载指令之间插入一条内存依赖屏障或者更强的内存屏障：

	CPU 1		      CPU 2
	===============	      ===============
	{ A == 1, B == 2, C == 3, P == &A, Q == &C }
	B = 4;
	<write barrier>
	WRITE_ONCE(P, &B);
			      Q = READ_ONCE(P);
			      <data dependency barrier>
			      D = *Q;

这样能够保证最终结果为两种预期结果之一，并且避免第三种可能的结果出现。

[!] 注意这种极度违反直觉的场景很容易出现在那些具有分离缓存的机器上，比如一路缓存处理偶数
编号的缓存行，另一路缓存处理具有奇数编号的缓存行。指针P可能存储在一条奇数编号的缓存行中，
变量B可能存储在一条偶数编号的缓存行中。当CPU处理偶数编号的缓存非常繁忙且处理奇数编号的缓
存空闲时，有可能可以观测到指针P（&B）具有新的值，但是变量B（2）仍然保存旧的值。

当需要对具有依赖关系的写操作进行排序时不需要使用数据依赖屏障，因为Linux内核支持的CPU不会
进行写入，直到CPU能够确定（1）写操作会实际发生，（2）写操作的地址能够确定，（3）写入的值
能够确定。但是请仔细阅读“控制依赖”一节和Documentation/RCU/rcu_dereference.rst：编译器
通过非常多的高度创新的方式能够并且确实破坏了这种依赖性。

	CPU 1		      CPU 2
	===============	      ===============
	{ A == 1, B == 2, C = 3, P == &A, Q == &C }
	B = 4;
	<write barrier>
	WRITE_ONCE(P, &B);
			      Q = READ_ONCE(P);
			      WRITE_ONCE(*Q, 5);

因此，不需要通过数据依赖屏障对Q的加载操作和*Q的存储操作进行排序。换句话说，这种结果是禁
止的，即使没有使用数据依赖屏障：

	(Q == &B) && (B == 4)

请注意这种方式非常的罕见。毕竟，所有根据依赖关系排序的出发点都是阻止写入数据结构以及与这
些写入一起引入的昂贵的缓存丢失开销。这种方式可以用来记录罕见的错误场景，并且CPU本身的排
序能够阻止这些记录的丢失。

注意数据依赖所带来的顺序仅仅对包含该操作的本地CPU生效。更多的信息参考“多重复制的原子性”
一节。

数据依赖屏障对于RCU系统非常重要。参考include/linux/rcupdate.h中rcu_assign_pointer()
和rcu_dereference()的实现。它能够允许使用一个新的目标替换RCU指针指向的当前目标，而不会
让替换的目标看起来没有完全没有初始化。

可以参考“缓存一致性”子节获取更加完整的关于数据依赖屏障的示例。


控制依赖
-------

控制依赖可能有些难以理解，因为当前的编译器不能识别到它们。本节的目的在于帮助你避免因为编
译器对于控制依赖的忽视而引起的代码问题。

一个加载-加载操作间的控制依赖需要一条完整的读内存屏障来保证它正常工作，而不是一条简单的
数据依赖屏障。考虑下边的代码：

	q = READ_ONCE(a);
	if (q) {
		<data dependency barrier>  /* BUG: No data dependency!!! */
		p = READ_ONCE(b);
	}

这不会产生想要的效果，因为这里实际上没有真正的数据依赖；但是存在控制依赖，因为CPU可能会
尝试通过提前预测结果来简化执行路径，从而导致其他CPU观察到对于b的加载发生在a的加载之前。
在这种场景下实际上需要：

	q = READ_ONCE(a);
	if (q) {
		<read barrier>
		p = READ_ONCE(b);
	}

然而存储操作没有预测到。这意味着顺序是由读取-存储控制依赖保证的，比如在下边的示例中：

	q = READ_ONCE(a);
	if (q) {
		WRITE_ONCE(b, 1);
	}

正常情况下控制依赖需要和其他屏障成对使用。请注意这意味着不管READ_ONCE()还是WRITE_ONCE()
都不是可选项！如果没有使用READ_ONCE()，编译器可能会将这里对于‘a’的加载操作和其他地方对于
‘a’的加载操作进行合并。如果没有使用WRITE_ONCE()，编译器可能将这里对于‘b’的存储操作和其他
对于‘b’的存储操作进行合并。无论是哪种场景都会对执行顺序产生非常反直觉的作用。

更糟糕的是，如果编译器能够证明变量‘a’的值永远为0，那么在它的权限范围内可能会将原始示例中
的if语句优化掉，如下：

	q = a;
	b = 1;  /* BUG: Compiler and CPU can both reorder!!! */

所以不要省略READ_ONCE()。

对“if"两个分支中同样的存储语句进行强制保序看起来是合理的，比如：

	q = READ_ONCE(a);
	if (q) {
		barrier();
		WRITE_ONCE(b, 1);
		do_something();
	} else {
		barrier();
		WRITE_ONCE(b, 1);
		do_something_else();
	}

不幸的是，当前的编译器采用高级别的优化时会将上述代码转换为：

	q = READ_ONCE(a);
	barrier();
	WRITE_ONCE(b, 1);  /* BUG: No ordering vs. load from a!!! */
	if (q) {
		/* WRITE_ONCE(b, 1); -- moved up, BUG!!! */
		do_something();
	} else {
		/* WRITE_ONCE(b, 1); -- moved up, BUG!!! */
		do_something_else();
	}

现在对于a的加载和对于b的存储操作之间没有条件关系了，这意味着CPU有权利对这两条指令进行重
新排序：这里条件语句是绝对必须的，因此即使应用了所有的编译器优化也必须在汇编语句中体现这
里条件关系。因此，如果在这个示例中需要保序，你需要显式的使用内存屏障，比如使用
smp_store_release()：

	q = READ_ONCE(a);
	if (q) {
		smp_store_release(&b, 1);
		do_something();
	} else {
		smp_store_release(&b, 1);
		do_something_else();
	}

作为对比，如果没有显式的使用内存屏障，含有两个分支if语句只有在存储不同的数据时才能够保序，
比如：

	q = READ_ONCE(a);
	if (q) {
		WRITE_ONCE(b, 1);
		do_something();
	} else {
		WRITE_ONCE(b, 2);
		do_something_else();
	}

初始的READ_ONCE()任然是必须的，用来阻止编译器对于变量‘a’的优化。

除此以外，对于本地变量‘q’的使用需要额外小心，否则编译器可能会对‘q’的值进行猜测并且可能优
化掉所需要的条件语句。例如：

	q = READ_ONCE(a);
	if (q % MAX) {
		WRITE_ONCE(b, 1);
		do_something();
	} else {
		WRITE_ONCE(b, 2);
		do_something_else();
	}

如果MAX定义为1，那么编译器能够知道（q%MAX）等于0，在这种情况下编译器会将上述的代码转换
为：

	q = READ_ONCE(a);
	WRITE_ONCE(b, 2);
	do_something_else();

在这种代码变换的情况下，CPU可以不考虑变量‘a’的加载和变量‘b’的存储操作之间的顺序。看起来
添加一个barrier()可以解决这个问题，但是实际上没有任何帮助。条件语句已经优化掉了，编译器
屏障barrier()并不能恢复条件语句。因此，如果你依赖这里的内存顺序，你应该确保MAX大于1，或
许像下述代码：

	q = READ_ONCE(a);
	BUILD_BUG_ON(MAX <= 1); /* Order load from a with store to b. */
	if (q % MAX) {
		WRITE_ONCE(b, 1);
		do_something();
	} else {
		WRITE_ONCE(b, 2);
		do_something_else();
	}

请再次注意在不同的分支中存储到‘b’的数据不同。如果数据是相同的，就像在前文指出的一样，编
译器可能将这里的存储操作放到if语句的外边。

你必须小心不要过分的依赖常量布尔语句。考虑以下示例：

	q = READ_ONCE(a);
	if (q || 1 > 0)
		WRITE_ONCE(b, 1);

因为第一个条件不可能为假且第二个条件总是为真，编译器可能像下边这样进行代码转换，从而违反
控制依赖条件：

	q = READ_ONCE(a);
	WRITE_ONCE(b, 1);

这条示例强调了确保不要让编译器出格地理解你的代码的重要性。通常来讲，尽管READ_ONCE()强制
编译器真正的发出一条给定的加载操作，但是它并没有强制编译器使用加载指令的结果。

此外，控制依赖仅仅使用于需要关注的if语句中的then分支和else分支。尤其是它并不需要适用于
以下代码中的if语句：

	q = READ_ONCE(a);
	if (q) {
		WRITE_ONCE(b, 1);
	} else {
		WRITE_ONCE(b, 2);
	}
	WRITE_ONCE(c, 1);  /* BUG: No ordering against the read from 'a'. */

